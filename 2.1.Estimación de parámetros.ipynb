{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de parámetros en física de altas energías\n",
    "\n",
    "El mejor ajuste o __fitting__ es el ajuste más adecuado a los datos experimentales.\n",
    "\n",
    "En física de altas energías, el proósito principal es identificar a las partículas que se producen en los experimentos, que consiste en:\n",
    "\n",
    "1. Reconstrucción de las trazas que dejan las partículas, a partir de los datos crudos que proporciona un detector bien calibrado.\n",
    "\n",
    "2. Analizar los datos reconstruidos\n",
    "\n",
    "3. Ajuste a los datos (masa, anchura, etc.) que contienen tanto señal como background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición y propiedades de la estimación de parámetros\n",
    "\n",
    "Dos ingredientes básicos:\n",
    "\n",
    "1. __Estimación puntual__: Mejor estimación del valor de los parámetros reales (mejor conjetura).\n",
    "\n",
    "2. __Estimación de las incertidumbres de los parámetros__ (intervalo de confianza): Ajuste de funciones a los datos y estimación de su desviación estándar.\n",
    "\n",
    "Métodos utilizados:\n",
    "\n",
    "1. __Máxima verosimilitud__.\n",
    "\n",
    "2. __Mínimos cuadrados__.\n",
    "\n",
    "3. __Método bayesiano__.\n",
    "\n",
    "Características:\n",
    "\n",
    "1. N valores de $x=(x_1, x_2,...x_N)$ independientes y descritas por una función de densidad de probabilidad $f(x)$\n",
    "\n",
    "2. Estimar las características de $f(x)$ (valor medio, dispersión, etc.) o tener una hipótesis de la forma funcional de $f(x)$ con respecto a algún parámetro $\\theta$, es decir, estimar $f(x;\\theta)$ con $\\theta=(\\theta_q,\\theta_2,...,\\theta_N)$.\n",
    "\n",
    "Ejemplo: $f(x;m,b)=mx+b$\n",
    "\n",
    "__Estimador__: \n",
    "\n",
    "<!-- Función de los datos observados $x$ que nos dan valores $\\hat{\\theta}$ para el parámetro $\\theta$. -->\n",
    "\n",
    "__Propiedades de los estimadores__: \n",
    "\n",
    "1. Consistencia: Un estimador $\\hat{\\theta}$ es consistente si converge al valor real $\\theta$ al aumentar el número de mediciones $N$\n",
    "\n",
    "2. Parcialidad (o imparcialidad): Es la diferencia entre el valor de expectación del valor estimado y del parámetro real, es decir, $b=E[\\hat{\\theta}]-\\theta$.\n",
    "\n",
    "a. $E[\\hat{\\theta}]$ se toma de un conjunto de experimentos similares.\n",
    "\n",
    "b. Imparcialidad si $b=0$.\n",
    "\n",
    "c. Si $\\hat{\\theta}$ es parcial, se puede construir un nuevo estimador imparcial $\\hat{\\theta}'=\\hat{\\theta}-b$.\n",
    "\n",
    "3. Eficiencia: Un estimador es eficiente si su varianza $V[\\hat{\\theta}]$ (desviación estándar) es pequeña.\n",
    "\n",
    "__Límite de varianza mínimo (MVB)__\n",
    "\n",
    "Condición de Rao-Cramér-Frechet: $V[\\hat{\\theta}] \\le I(\\theta)^{-1}$ con:\n",
    "\n",
    "$I_{jk}=E\\left[\\sum_{i=0}^N \\frac{\\partial^2 ln f(x_i;\\theta)}{\\partial \\theta_j \\theta_k}\\right]$\n",
    "\n",
    "sumando sobre todos los datos la __matriz de información $I_{jk}$__\n",
    "\n",
    "$I_{jk}=-N\\int\\frac{\\partial^2 ln f(x_i;\\theta)}{\\partial \\theta_j \\theta_k} f dx = N\\int\\frac{1}{f}\\frac{\\partial f(x_i;\\theta)}{\\partial \\theta_j}\\frac{\\partial f(x_i;\\theta)}{\\partial \\theta_k}  dx$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de máxima verosimilitud (Likelihood)\n",
    "\n",
    "En un conjunto de $N$ datos con $x=(x_1, x_2,...x_N)$ independientes estadísticamente, que siguen la distribución de densidad de probabilidad $f(x;\\theta)$ donde $\\theta=(\\theta_q,\\theta_2,...,\\theta_N)$ es un conjunto de parámetros a estimar.\n",
    "\n",
    "La función de probabilidad de observar los valores $x$, está dada por la función de máxima verosimilitud.\n",
    "\n",
    "$L(x;\\theta)=\\prod_{i=0}^N f(x_i|\\theta)$\n",
    "\n",
    "El estimador de máxima verosimilitud de los parámetros $\\theta$, son los valores $\\hat{\\theta}$ para los cuales las función de verosimilitud tiene un máximo global.\n",
    "\n",
    "### Solución de máxima verosimilitud.\n",
    "\n",
    "La estimación de los parámetros $\\hat{\\theta}$ se obtine al maximizar la función de verosimilitud o su logaritmo,\n",
    "\n",
    "$-ln L(x;\\theta)=\\prod_{i=0}^N ln f(x_i|\\theta)$\n",
    "\n",
    "que satisfaga que:\n",
    "\n",
    "$-\\frac{\\partial ln L(x;\\hat{\\theta})}{\\partial \\theta_j}=0$\n",
    "\n",
    "y la función de probabilidad normalizada:\n",
    "\n",
    "$\\int f(x;\\theta)dx=1$ entonces $\\int L(x;\\theta)dx=1$; quiere decir que la integral de $L(x;\\theta)$ no depende de $\\theta$. \n",
    "\n",
    "### Propiedades del estimador de máxima verosimilitud\n",
    "\n",
    "1. $\\lim_{N\\to\\infty} \\hat{\\theta} = \\theta$\n",
    "\n",
    "2. Para $N$ finito es un estimador parcial de 1/N.\n",
    "\n",
    "3. Invariante ante transformaiones de parámetros: $\\psi=g(\\theta)$, entonces, $\\hat{\\psi}=g(\\hat{\\theta})$.\n",
    "\n",
    "### Máxima verosimilitud y método bayesiano.\n",
    "\n",
    "La función de densidad de probabilidad a posteriori $p(\\theta;x)$ involucra el producto de máxima verosimilitud $L(x;\\theta)$ y la probabilidad a priori $\\pi(\\theta)$ (Teorema bayesiano)\n",
    "\n",
    "$p(\\theta;x)=\\frac{L(x;\\theta )\\pi(\\theta)}{\\int L(x;\\theta) \\pi(\\theta)} d\\theta$\n",
    "\n",
    "En la estadística bayesiana, el estimador de máxima verosimilitud da los parámetros que coinciden con el máximo de la función a posteriori.\n",
    "\n",
    "#### Valor medio con error gaussiano\n",
    "\n",
    "$N$ mediciones con parámtro $\\theta$ dond $x_i$ tienen una distribución gaussiana\n",
    "\n",
    "$f(x_i;\\theta,\\sigma) = \\frac{1}{{\\sigma_i\\sqrt{2\\pi}}}e^{-\\frac{\\left(x_i-\\theta\\right) ^2}{2\\sigma_i^2}}$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$L(\\theta)=\\prod_{i=0}^N \\frac{1}{\\sigma_i \\sqrt{2\\pi}}e^{-\\frac{\\left(x_i-\\theta\\right)^2}{2\\sigma_i^2}} = \\frac{1}{({\\sigma_i\\sqrt{2\\pi}})^N}e^{-\\sum_{i=0}^N \\frac{\\left(x_i-\\theta\\right) ^2}{2\\sigma_i^2}}$\n",
    "\n",
    "$ln L(\\theta) =-N ln (\\sqrt{2\\pi}-N ln(\\sigma_i)-\\sum_{i=0}^N \\frac{(x_i-\\theta)^2}{2\\sigma_i^2}$\n",
    "\n",
    "$\\frac{\\partial ln L(\\theta)}{\\partial \\theta}=\\sum_{i=0}^N \\frac{(x_i-\\theta)}{\\sigma_i^2}$=0\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$\\sum_{i=0}^N x_i = N\\theta$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$\\theta=\\sum_{i=0}^N \\frac{x_i}{N}=\\bar{x}$ __es el valor medio de los datos__\n",
    "\n",
    "y haciendo el mismo cálculo para $\\sigma$ tenemos que \n",
    "\n",
    "$\\sigma^2=\\sum_{i=0}^N \\frac{(x_i-\\bar{x})^2}{N}$ __es la varianza de los datos__\n",
    "\n",
    "__Segunda derivada:__\n",
    "\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\theta}\\frac{\\partial ln L(\\theta)}{\\partial \\theta}=\\sum_{i=0}^N \\frac{\\partial}{\\partial\\theta}\\frac{(x_i-\\theta)}{\\sigma_i^2}=-\\sum_{i=0}^N \\frac{1}{\\sigma^2}=cte=h$\n",
    "\n",
    "entonces, $\\sigma_{\\theta}=\\frac{1}{h}$ por lo que la función de máxima verosimilitud se puede escribir como:\n",
    "\n",
    "$ln L(\\theta)=ln L(\\hat{\\theta}) -\\frac{h}{2}(\\theta-\\hat{\\theta})^2$\n",
    "\n",
    "y por lo tanto:\n",
    "\n",
    "$L(\\theta) \\propto exp(-\\frac{h}{2}(\\theta-\\hat{\\theta})^2$\n",
    "\n",
    "$\\hat{\\theta}$ va a estar alrededor de $\\theta$ con una varianza $1/h$ del máximo valor de $\\sigma_{\\theta}$ y decrece hasta 1/2\n",
    "\n",
    "## Varianza del estimador de máxima verosimilitud\n",
    "\n",
    "Cuando se incrementa el número de eventos, cualquier función de densidad de probabilidad, se aproxima a una distribución gaussiana multivariante. Entonces $L$ puedes escribirse como:\n",
    "\n",
    "$L\\propto exp(-\\frac{1}{2}(\\theta-\\hat{\\theta})^T H (\\theta-\\hat{\\theta}))$\n",
    "\n",
    "y la varianza:\n",
    "\n",
    "$V[\\hat{\\theta}]\\rightarrow I(\\theta)^{-1}$ con\n",
    "\n",
    "$I_{jk}=-E\\left(\\frac{\\partial^2 ln L}{\\partial \\theta_j \\partial \\theta_k}\\right)=H$\n",
    "\n",
    "y la matriz de covarianza:\n",
    "\n",
    "$\\hat{V}(\\hat{\\theta})=\\left[-\\frac{\\partial^2 ln L(x;\\theta)}{\\partial \\theta^2}|_{\\theta=\\hat{\\theta}}\\right]^{-1}=H^{-1}$\n",
    "\n",
    "y para cada parámetro $\\hat{\\theta_j}$:\n",
    "\n",
    "$\\hat{\\sigma}_{\\theta_j}=\\sqrt{\\hat{V}_{jj}(\\hat{\\theta})}$\n",
    "\n",
    "También se puede utilizar el valor de $s\\sigma$ ($1\\sigma=68\\%$):\n",
    "\n",
    "$\\Delta ln L(\\theta)=-\\frac{s^2}{2}$\n",
    "\n",
    "entonces se calcula el valor mínimo $\\theta_{low}=\\hat{\\theta}-\\Delta\\hat{\\theta}_-$ y el valor máximo $\\theta{max}=\\hat{\\theta}+\\Delta\\hat{\\theta}_+$ para los cuales se cumpla la condición $\\Delta ln L(\\theta)=-\\frac{1}{2}$ y entonce:\n",
    "\n",
    "$\\theta=\\hat{\\theta}_{\\Delta\\hat{\\theta}_-}^{\\Delta\\hat{\\theta}_+}=\\hat{\\theta}\\pm\\hat{\\sigma}_{\\theta}$\n",
    "\n",
    "          \n",
    "### Región de confianza con $\\chi^2$\n",
    "\n",
    "Para evaluar la región de confianza $\\Delta ln L(\\theta)=-\\frac{s^2}{2}$ se define la razon de la función de máxima verosimilitud:\n",
    "\n",
    "$\\lambda(\\theta)=\\frac{L(x;\\theta)}{L(x;\\hat{\\theta})}$\n",
    "\n",
    "\n",
    "Para una muestra grande donde la función de máxima verosimilitud se aproxima a una distribución de probabilidad gaussiana, $-2 ln \\lambda(\\theta)$ se aproxima a una distribución $\\chi^2$ para evaluar la región de confianza $1-\\alpha$ donde $\\alpha$ es el valor medio de la distribución.\n",
    "\n",
    "Estos intervalos regulares (cuantiles $1-\\alpha$) definen el crecimiento de $-2 ln \\lambda(\\theta)$ que corresponden a los valores de $\\theta$ en los bordes de la región de confianza.\n",
    "\n",
    "El valor de los cuantiles es de la forma $F_{\\chi^2}^{-1}(1-\\alpha,m)$ que es el inverso de la función acumulativa $F_{\\chi^2}$ para la función $\\chi^2$ con $m$ grados de \n",
    "\n",
    "### Perfil de verosimilitud\n",
    "\n",
    "Si la función depende de varios parámetros, pero solo se quiere obtener uno de ellos:\n",
    "\n",
    "$\\lambda(\\mu)=\\frac{L(x;\\mu,\\hat{\\hat{\\theta}})}{L(x;\\hat{\\mu},\\hat{\\theta})}$\n",
    "\n",
    "1. En el numerador el parámetro $\\theta$ se ajuste mediante el estimador de máxima verosimilitud a $\\hat{\\hat{{\\theta}}}$ para un valor dado de $\\mu$.\n",
    "\n",
    "2. En el denominador $\\mu$ se ajusta con el estimador de máxima verosimilitud a los valores $ḩat{\\mu}$ y $\\hat{\\theta}$\n",
    "\n",
    "3. $-2 ln(\\lambda(u))$ sigue una distibución $\\chi^2$ y el intervalo de confianza de $\\mu$ se obtine con $-\\Delta L = -s^2/2$\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
